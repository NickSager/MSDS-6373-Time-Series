---
title: "Time Series Project"
subtitle: "Spring 2024"
author: "Nicholas Sager, Anishka Peter"
date: last-modified
format: 
  html: 
    toc: true
    toc-location: left
    toc-depth: 4
    embed-resources: true
    # self-contained-math: true
---

```{r setup, include=FALSE}
library(tidyverse)
library(tswge)
library(nnfor)
library(vars)
library(tseries)
# library(orcutt)
```

## Data
Introduce dataset, response variable, and scenario.
ACFs and Spectral Density plots.
```{r}
library(dplyr)
library(lubridate)
bike_data <- read_csv("https://raw.githubusercontent.com/NickSager/MSDS-6373-Time-Series/master/Project/bike_data.csv")

plotts.sample.wge(bike_data$`Total Users`)$xbar

# make the bike data daily instead of hourly 
daily_bike_data <- bike_data %>%
  group_by(Date = as.Date(Date, format = "%m/%d/%Y")) %>%
  summarise(
    Season = mean(Season),
    Hour = mean(Hour),
    Holiday = mean(Holiday),
    Day_of_the_Week = mean(`Day of the Week`),
    Working_Day = mean(`Working Day`),
    Weather_Type = mean(`Weather Type`),
    Temperature = mean(`Temperature F`),
    Temperature_Feels = mean(`Temperature Feels F`),
    Humidity = mean(Humidity),
    Wind_Speed = mean(`Wind Speed`),
    Casual_Users = sum(`Casual Users`),
    Registered_Users = sum(`Registered Users`),
    Total_Users = sum(`Total Users`), 
  )

plotts.sample.wge(daily_bike_data$Total_Users)$xbar
```


## Models
### Univariate: At least 2 candidate ARMA / ARIMA models

#### Seasonal Model 
```{r}
# create model 
plotts.sample.wge(daily_bike_data$Total_Users)$xbar # looking at the ACF's there seems to be a seasonality of 2
factor.wge(phi = c(0,1)) 
est.arma.wge(daily_bike_data$Total_Users, p = 15) # looking at the overfit tables there's evidence of seasonality of 2 
diff= artrans.wge(daily_bike_data$Total_Users, phi.tr = c(0,1))
aic5.wge(diff,type = 'bic') # bic picked p = 2 and q = 2
seasonal_est = est.arma.wge(diff, p = 2, q = 2)

# Checking the residuals to see if the model is appropriate 
plotts.wge(seasonal_est$res) # looks random
acf(seasonal_est$res) # all the acfs are within the bounds 
ljung.wge(seasonal_est$res) # greater than 0.05
ljung.wge(seasonal_est$res, K =48) # greater than 0.05
seasonal_gen1 = gen.arima.wge(200, phi = seasonal_est$phi, theta = seasonal_est$theta, s = 2)
seasonal_gen2 = gen.arima.wge(200, phi = seasonal_est$phi, theta = seasonal_est$theta, s = 2)
seasonal_gen3 = gen.arima.wge(200, phi = seasonal_est$phi, theta = seasonal_est$theta, s = 2)
seasonal_gen4 = gen.arima.wge(200, phi = seasonal_est$phi, theta = seasonal_est$theta, s = 2)
plotts.sample.wge(seasonal_gen1)$xbar
plotts.sample.wge(seasonal_gen2)$xbar
plotts.sample.wge(seasonal_gen3)$xbar
plotts.sample.wge(seasonal_gen4)$xbar # all these 4 random realizations have the same behavior as the original data so the model seems to be appropriate

```
$$\phi(B)(1-B^2) = \theta(B)$$
$$(1-0.1669356B-0.2335503B^2)(1-B^2) = (1- 0.005624988B- 0.823629022B^2)$$

```{r}
# plot of Last N forecasts for short and long term horizon 
seasonal_stfore1 = fore.arima.wge(daily_bike_data$Total_Users, phi = seasonal_est$phi, theta = seasonal_est$theta, s = 2, n.ahead = 7, lastn = TRUE)
seasonal_ltfore1 = fore.arima.wge(daily_bike_data$Total_Users, phi = seasonal_est$phi, theta = seasonal_est$theta, s = 2, n.ahead = 60, lastn = TRUE)

t = 1:length(daily_bike_data$Total_Users)
plot(t[720:731],daily_bike_data$Total_Users[720:731], type = 'l', xlab = "Time", ylab = "Total Users")
points(t[725:731], seasonal_stfore1$f, type="l", lwd=2, lty = 2, col = 'blue')

plot(t[670:731],daily_bike_data$Total_Users[670:731], type = 'l', xlab = "Time", ylab = "Total Users")
points(t[672:731], seasonal_ltfore1$f, type="l", lwd=2, lty = 2,col = 'blue')

# ASE 
seasonal_stASE = mean((daily_bike_data$Total_Users[725:731]-seasonal_stfore1$f)^2)
seasonal_ltASE = mean((daily_bike_data$Total_Users[672:731]-seasonal_ltfore1$f)^2)
seasonal_stASE
seasonal_ltASE

# Rolling Window RMSE
# RW-RMSE commented out due to obscene amount of unsupressable output
# seasonal_strwRMSE = roll.win.rmse.wge(daily_bike_data$Total_Users, horizon = 7, phi = seasonal_est$phi, theta = seasonal_est$theta, s = 2)$rwRMSE
# seasonal_ltrwRMSE = roll.win.rmse.wge(daily_bike_data$Total_Users, horizon = 60, phi = seasonal_est$phi, theta = seasonal_est$theta, s = 2)$rwRMSE

seasonal_strwRMSE = 1253.353
seasonal_ltrwRMSE = 1504.218

seasonal_stfore2 = fore.arima.wge(daily_bike_data$Total_Users, phi = seasonal_est$phi, theta = seasonal_est$theta, s = 2, n.ahead = 7)
seasonal_ltfore2 = fore.arima.wge(daily_bike_data$Total_Users, phi = seasonal_est$phi, theta = seasonal_est$theta, s = 2, n.ahead = 60)


# Plots of the short and Long Term Forecasts  
t = 1:800
plot(t[670:731],daily_bike_data$Total_Users[670:731], type = 'l', main = "Short Term Forecast", xlim = c(670,795), xlab = "Time", ylab = "Total Users")
points(t[732:738],seasonal_stfore2$f, type = 'l', col = 'blue')
points(t[732:738],seasonal_stfore2$ll, type = 'l',lwd=2, lty = 2, col = 'red')
points(t[732:738],seasonal_stfore2$ul, type = 'l',lwd=2, lty = 2, col = 'red')


plot(t[670:731],daily_bike_data$Total_Users[670:731], type = 'l', main = "Long Term Forecast", xlim = c(670,795), xlab = "Time", ylab = "Total Users")
points(t[732:791],seasonal_ltfore2$f, type = 'l', col = 'blue')
points(t[732:791],seasonal_ltfore2$ll, type = 'l',lwd=2, lty = 2, col = 'red')
points(t[732:791],seasonal_ltfore2$ul, type = 'l',lwd=2, lty = 2, col = 'red')

```

### Non-Seasonal ARIMA Model
```{r}
# Check if the data could be stationary
adf.test(daily_bike_data$Total_Users) # p-value 0.7, data not likely stationary

# Difference of 1
total_d1 = artrans.wge(daily_bike_data$Total_Users, phi.tr = c(1))

# Model the residuals
aic5.wge(total_d1, type = 'bic') # bic and aic pick p = 1 and q = 1
est = est.arma.wge(total_d1, p = 1, q = 1)
plotts.sample.wge(est$res, arlimits = TRUE)$xbar # appears to be white noise
ljung.wge(est$res) # FTR
ljung.wge(est$res, K = 48) # Reject. Mixed evidence.

# Generate realizations for comparison
arima_gen1 = gen.arima.wge(200, phi = est$phi, theta = est$theta, d = 1)
arima_gen2 = gen.arima.wge(200, phi = est$phi, theta = est$theta, d = 1)
arima_gen3 = gen.arima.wge(200, phi = est$phi, theta = est$theta, d = 1)
arima_gen4 = gen.arima.wge(200, phi = est$phi, theta = est$theta, d = 1)
plotts.sample.wge(arima_gen1)$xbar
plotts.sample.wge(arima_gen2)$xbar
plotts.sample.wge(arima_gen3)$xbar
plotts.sample.wge(arima_gen4)$xbar # Similar behavior to original data

# Compare Spectral Densities: 
sims = 20
SpecDen = parzen.wge(daily_bike_data$Total_Users, plot = "FALSE")
plot(SpecDen$freq,SpecDen$pzgram, type = "l", lwd = 6)

for( i in 1: sims)
{
   SpecDen2 = parzen.wge(gen.aruma.wge(length(daily_bike_data$Total_Users), d = 1, phi = est$phi, theta = est$theta, plot ="FALSE"), plot = "FALSE")
   lines(SpecDen2$freq,SpecDen2$pzgram, lwd = 2, col = "red")
}

# Compare ACFs:
sims = 20
ACF = acf(daily_bike_data$Total_Users, plot = "FALSE")
plot(ACF$lag ,ACF$acf , type = "l", lwd = 6)

for( i in 1: sims)
{
   ACF2 = acf(gen.aruma.wge(length(daily_bike_data$Total_Users), d = 1, phi = est$phi, theta = est$theta, plot ="FALSE"), plot = "FALSE")
   lines(ACF2$lag ,ACF2$acf, lwd = 2, col = "red")
}

# Short and Long Term Forecasts
fore_arima_st = fore.arima.wge(daily_bike_data$Total_Users, phi = est$phi, theta = est$theta, d = 1, n.ahead = 7, lastn = TRUE)
fore_arima_lt = fore.arima.wge(daily_bike_data$Total_Users, phi = est$phi, theta = est$theta, d = 1, n.ahead = 60, lastn = TRUE)

# Plot Forecasts and CI
t = 1:length(daily_bike_data$Total_Users)
plot(t[720:731],daily_bike_data$Total_Users[720:731], type = 'l', xlab = "Time", ylab = "Total Users")
points(t[725:731], fore_arima_st$f, type="l", lwd=2, lty = 2, col = 'blue')

plot(t[670:731],daily_bike_data$Total_Users[670:731], type = 'l', xlab = "Time", ylab = "Total Users")
points(t[672:731], fore_arima_lt$f, type="l", lwd=2, lty = 2,col = 'blue')

# ASE 
arima_stASE = mean((daily_bike_data$Total_Users[725:731]-fore_arima_st$f)^2)
arima_ltASE = mean((daily_bike_data$Total_Users[672:731]-fore_arima_lt$f)^2)
arima_stASE
arima_ltASE

# Rolling Window RMSE
# RW-RMSE commented out due to obscene amount of unsupressable output
# arima_strwRMSE = roll.win.rmse.wge(daily_bike_data$Total_Users, horizon = 7, phi = est$phi, theta = est$theta, d = 1)$rwRMSE
# arima_ltrwRMSE = roll.win.rmse.wge(daily_bike_data$Total_Users, horizon = 60, phi = est$phi, theta = est$theta, d = 1)$rwRMSE
arima_strwRMSE = 1237.393
arima_ltrwRMSE = 1503.197

# Plots of the short and Long Term Forecasts  
fore_arima_st_2 = fore.arima.wge(daily_bike_data$Total_Users, phi = est$phi, theta = est$theta, d = 1, n.ahead = 7)
fore_arima_lt_2 = fore.arima.wge(daily_bike_data$Total_Users, phi = est$phi, theta = est$theta, d = 1, n.ahead = 60)

t = 1:800
plot(t[670:731],daily_bike_data$Total_Users[670:731], type = 'l', main = "Short Term Forecast", xlim = c(670,795), xlab = "Time", ylab = "Total Users")
points(t[732:738],fore_arima_st_2$f, type = 'l', col = 'blue')
points(t[732:738],fore_arima_st_2$ll, type = 'l',lwd=2, lty = 2, col = 'red')
points(t[732:738],fore_arima_st_2$ul, type = 'l',lwd=2, lty = 2, col = 'red')


plot(t[670:731],daily_bike_data$Total_Users[670:731], type = 'l', main = "Long Term Forecast", xlim = c(670,795), xlab = "Time", ylab = "Total Users")
points(t[732:791],fore_arima_lt_2$f, type = 'l', col = 'blue')
points(t[732:791],fore_arima_lt_2$ll, type = 'l',lwd=2, lty = 2, col = 'red')
points(t[732:791],fore_arima_lt_2$ul, type = 'l',lwd=2, lty = 2, col = 'red')
```



a.	The models in factored form or at least separate the stationary and non-
stationary factors with standard deviation or variance of the white noise.
b.	AIC
c.	ASE (short and long term forecasts)
d.	Rolling Window RMSE (short and long term forecasts)
e.	At least 10 superimposed spectral densities from 10 generated 
realizations like we did in Unit 11.  Use these to help choose between the at least two candidate univariate models. 
f.	Visualization of Forecasts for both the short- and long-term Horizons. 
g.	Be sure and include confidence intervals when possible (I don’t have 
code for confidence intervals from MLP models at the moment… but that would be a good thing to work on!  )

### Multivariate: At least one multivariate model (VAR or MLR with Correlated Errors)
i.	Include an ASE (rolling window is not yet available in multivariate models)
  1.	Short Horizon (you pick the length.. could be one step ahead)
  2.	Long Horizon (you pick ... just must be longer than the short horizon.)
ii.	Describe the explanatory variable(s) used in the model and why you felt they were significant / important.
iii.	Visualization of Forecasts for both the short- and long-Horizons.
iv.	Be sure and include confidence intervals if using VAR … 


```{r}
ccf(daily_bike_data$Total_Users,daily_bike_data$Humidity) # lag of 5 
daily_bike_data$Humidity_lag = dplyr::lag(daily_bike_data$Humidity,5)

fit = lm(Total_Users~Humidity_lag + Temperature + Temperature_Feels + Day_of_the_Week + Wind_Speed, data = daily_bike_data)

plotts.sample.wge(fit$residuals)$xbar
aic5.wge(fit$residuals, p =0:10, q = 0:5, type = 'bic')
mlr = arima(daily_bike_data$Total_Users, order = c(6,0,1),xreg = cbind(daily_bike_data$Humidity_lag, daily_bike_data$Temperature, daily_bike_data$Temperature_Feels, daily_bike_data$Day_of_the_Week, daily_bike_data$Wind_Speed))


plotts.wge(mlr$residuals) # looks random
acf(mlr$residuals[-(1:5)]) # only 1/20 acfs out of bounds 
ljung.wge(mlr$residuals) # greater than 0.05
ljung.wge(mlr$residuals, K =48)


mlr_st_pred = predict(mlr, newxreg = data.frame(daily_bike_data$Humidity_lag[725:731], daily_bike_data$Temperature[725:731], daily_bike_data$Temperature_Feels[725:731], daily_bike_data$Day_of_the_Week[725:731], daily_bike_data$Wind_Speed[725:731]), n.ahead = 7, lastn= TRUE)

plot(seq(1,731,1),daily_bike_data$Total_Users,type = 'l',xlim = c(720,731))
points(seq(725,731,1),mlr_st_pred$pred,type = 'b', pch = 15)

mlr_st_ASE= mean((daily_bike_data$Total_Users[725:731] - mlr_st_pred$pred)^2)

mlr_st_ASE

mlr_lt_pred = predict(mlr, newxreg = data.frame(daily_bike_data$Humidity_lag[672:731], daily_bike_data$Temperature[672:731], daily_bike_data$Temperature_Feels[672:731], daily_bike_data$Day_of_the_Week[672:731], daily_bike_data$Wind_Speed[672:731]), n.ahead = 60, lastn= TRUE)

plot(seq(1,731,1),daily_bike_data$Total_Users,type = 'l',xlim = c(670,731))
points(seq(672,731,1),mlr_lt_pred$pred,type = 'b', pch = 15)

mlr_lt_ASE= mean((daily_bike_data$Total_Users[672:731] - mlr_lt_pred$pred)^2)

mlr_lt_ASE



mlr_st_pred2 = predict(mlr, newxreg = data.frame(daily_bike_data$Humidity_lag[725:731], daily_bike_data$Temperature[725:731], daily_bike_data$Temperature_Feels[725:731], daily_bike_data$Day_of_the_Week[725:731], daily_bike_data$Wind_Speed[725:731]), n.ahead = 7, lastn= FALSE)
plot(seq(1,731,1),daily_bike_data$Total_Users,type = 'l',xlim = c(720,738), main = "Short Term MLR Forecast")
points(seq(732,738,1),mlr_st_pred2$pred,type = 'b', pch = 15,col = 'blue')

mlr_lt_pred2 = predict(mlr, newxreg = data.frame(daily_bike_data$Humidity_lag[672:731], daily_bike_data$Temperature[672:731], daily_bike_data$Temperature_Feels[672:731], daily_bike_data$Day_of_the_Week[672:731], daily_bike_data$Wind_Speed[672:731]), n.ahead = 60, lastn= FALSE)
plot(seq(1,731,1),daily_bike_data$Total_Users,type = 'l',xlim = c(720,785), main = "Long Term MLR Forecast")
points(seq(732,791,1),mlr_lt_pred2$pred,type = 'b', pch = 15,col = 'blue')
```

```{r}
VARselect(daily_bike_data[,c(5,8:11,14)])
fit2 = VAR(daily_bike_data[,c(5,8:11,14)], p = 10, type = 'both')


plotts.wge(fit2$varresult$Total_Users$residuals)
acf(fit2$varresult$Total_Users$residuals)
ljung.wge(fit2$varresult$Total_Users$residuals, p = 10)
ljung.wge(fit2$varresult$Total_Users$residuals, p = 10, K = 48)

var_st_pred = predict(fit2, n.ahead = 7, lastn = TRUE)

t = 1:731
plot(seq(1,731,1),daily_bike_data$Total_Users,type = 'l',xlim = c(670,731))
points(t[725:731], var_st_pred$fcst$Total_Users[,1], type="l", lwd=2, lty = 1)

var_st_ase = mean((daily_bike_data$Total_Users[725:731]-var_st_pred$fcst$Total_Users[,1])^2)
var_st_ase

var_lt_pred = predict(fit2, n.ahead = 60, lastn = TRUE)

t = 1:731
plot(seq(1,731,1),daily_bike_data$Total_Users,type = 'l',xlim = c(672,731))
points(t[672:731], var_lt_pred$fcst$Total_Users[,1], type="l", lwd=2, lty = 1)

var_lt_ase = mean((daily_bike_data$Total_Users[672:731]-var_lt_pred$fcst$Total_Users[,1])^2)
var_lt_ase


var_st_pred2 = predict(fit2, n.ahead = 7, lastn = FALSE)

t = 1:800
plot(seq(1,731,1),daily_bike_data$Total_Users,type = 'l',xlim = c(670,738), main = "Short Term VAR Forecast")
points(t[732:738], var_st_pred2$fcst$Total_Users[,1], type="l", lwd=2, lty = 1, col = 'blue')

var_lt_pred2 = predict(fit2, n.ahead = 60, lastn = FALSE)

t = 1:800
plot(seq(1,731,1),daily_bike_data$Total_Users,type = 'l',xlim = c(670,791), main = "Long Term VAR Forecast")
points(t[732:791], var_lt_pred2$fcst$Total_Users[,1], type="l", lwd=2, lty = 1, col = 'blue')

```



### MLP Model
i.	ASE (short and long term forecasts)
ii.	Rolling Window RMSE (short and long term forecasts (only if univariate)
iii.	Visualization of Forecasts for both the short- and long-term Horizons. 
iv.	Confidence / Prediction intervals are not required (I don’t have 
code for confidence / prediction intervals (bootstrap intervals) for MLP models at the moment… but that would be a good thing to work on!  )

### Ensemble Model

## Model Comparison and Final Forecasts
i.	Provide a table comparing all models on at least ASE and rwRMSE (if available).
ii.	Include at least one ensemble model in addition to the models above.
iii.	Make a case as to why you feel one of your candidate models is the most useful.
iv.	Provide you final short and long term forecasts with that model. 


## Conclusion
